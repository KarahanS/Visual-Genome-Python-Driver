{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karab\\AppData\\Local\\Temp\\ipykernel_17904\\813984115.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from visual_genome.local import VisualGenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script directory: C:\\Users\\karab\\Desktop\\Visual Genome Driver\\visual_genome\n",
      "Data directory: C:\\Users\\karab\\Desktop\\Visual Genome Driver\\data\n",
      "Loading data...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "vg = VisualGenome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1002\n"
     ]
    }
   ],
   "source": [
    "ims = []\n",
    "\n",
    "with open('filtered_images_2.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        ims.append(line.strip())\n",
    "\n",
    "ims = [int(im) for im in ims]\n",
    "print('Number of images:', len(ims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS BLOCK IF YOU HAVE SAM, SAM2 RESULTS IN THE DATA DIRECTORY - otherwise skip\n",
    "vg.load_sam_results(version=1) # SAM\n",
    "vg.load_sam_results(version=2) # SAM 2\n",
    "vg.load_fc_clip_results() # FC-CLIP\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1002\n"
     ]
    }
   ],
   "source": [
    "ims = []\n",
    "with open('filtered_images_2.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        ims.append(line.strip())\n",
    "\n",
    "ims = [int(im) for im in ims]\n",
    "print('Number of images:', len(ims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_visualize(vg, ims, n=1, include_regions=False):\n",
    "    for i in range(n):\n",
    "        im = random.choice(ims)\n",
    "        scene_graph = vg.generate_scene_graph_json(im, include_regions=include_regions)\n",
    "\n",
    "        # save to graph.json\n",
    "        if i >= 1:\n",
    "            filename = f\"../graphviz/scene_graph{i}.json\"\n",
    "        else:\n",
    "            filename = f\"../graphviz/scene_graph.json\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(scene_graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 3\n",
    "INCLUDE_REGIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomly_visualize(vg, ims=ims, n=COUNT, include_regions=INCLUDE_REGIONS)\n",
    "!python ../graphviz/visualize_scene_graph.py -n {COUNT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pairwise_visualize(vg, ims, n_pairs=1, include_regions=False):\n",
    "    for i in range(n_pairs):\n",
    "        im1 = random.choice(ims)\n",
    "        im2 = random.choice(ims)\n",
    "        \n",
    "        scene_graph1 = vg.generate_scene_graph_json(im1, include_regions=include_regions)\n",
    "        scene_graph2 = vg.generate_scene_graph_json(im2, include_regions=include_regions)\n",
    "        combined = {\"im1\": scene_graph1, \"im2\": scene_graph2}\n",
    "        # save to graph.json\n",
    "        if i >= 1:\n",
    "            filename = f\"../graphviz/scene_graph_combined{i}.json\"\n",
    "        else:\n",
    "            filename = f\"../graphviz/scene_graph_combined.json\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(combined, f)\n",
    "            \n",
    "pairwise_visualize(vg, ims=ims, n_pairs=2, include_regions=INCLUDE_REGIONS)\n",
    "!python ../graphviz/pairwise_comparison.py -n {2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Correlation between other features #############\n",
    "\n",
    "# get features.csv\n",
    "df_feat = pd.read_csv('features.csv')\n",
    "\n",
    "# get correlation of all features on a heatmap\n",
    "# create a heatmap of correlations between all features\n",
    "df_feat[\"avg_object_similarity\"] *= -1\n",
    "df_feat[\"avg_region_similarity\"] *= -1\n",
    "df_feat[\"avg_rel_similarity\"] *= -1\n",
    "\n",
    "def print_cors(df_feat):\n",
    "    print(\"Correlation between:\")\n",
    "    print(\"Predicted complexity and # of SAM 2 segmentations: \", df_feat['predicted_complexity'].corr(df_feat['# of SAM 2 segmentations'], method='spearman'))\n",
    "    print(\"Predicted complexity and # of SAM segmentations: \", df_feat['predicted_complexity'].corr(df_feat['# of SAM segmentations'], method='spearman'))\n",
    "    print(\"Predicted complexity and # of FC-CLIP segmentations: \", df_feat['predicted_complexity'].corr(df_feat['# of FC-CLIP classes'], method='spearman'))\n",
    "    print(\"Predicted complexity and average object dissimilarity: \", df_feat['predicted_complexity'].corr(df_feat['avg_object_similarity'], method='spearman'))\n",
    "    print(\"Predicted complexity and average region dissimilarity: \", df_feat['predicted_complexity'].corr(df_feat['avg_region_similarity'], method='spearman'))\n",
    "    print(\"Predicted complexity and average relationship dissimilarity: \", df_feat['predicted_complexity'].corr(df_feat['avg_rel_similarity'], method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between:\n",
      "Predicted complexity and # of SAM 2 segmentations:  0.7929978046466357\n",
      "Predicted complexity and # of SAM segmentations:  0.8594621800109393\n",
      "Predicted complexity and # of FC-CLIP segmentations:  0.7739138548434051\n",
      "Predicted complexity and average object dissimilarity:  0.16555065662803908\n",
      "Predicted complexity and average region dissimilarity:  0.5225703352981856\n",
      "Predicted complexity and average relationship dissimilarity:  0.5208962993656996\n"
     ]
    }
   ],
   "source": [
    "# get only the images in suitables\n",
    "df_new = df_feat[df_feat['image_id'].isin(ims)]\n",
    "print_cors(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE YOU CAN VISUALIZE THE IMAGES IN THE SUBSAMPLE BELONGING TO A SPECIFIC CLUSTER \n",
    "\n",
    "df_cluster = pd.read_csv('categories_all-mpnet-base-v2_80clusters_simple.csv')\n",
    "\n",
    "# get images in a cluster\n",
    "def get_images_in_cluster(cluster_id, df_cluster, ims):\n",
    "    images = []\n",
    "    for i in range(len(df_cluster)):\n",
    "        if df_cluster['cluster'][i] == cluster_id:\n",
    "            if df_cluster['Image_id'][i] in ims:\n",
    "                images.append(df_cluster['Image_id'][i])\n",
    "    return images\n",
    "\n",
    "cluster_images_from_sample = get_images_in_cluster(6, df_cluster, ims)\n",
    "len(cluster_images_from_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in cluster_images_from_sample:\n",
    "    vg.visualize_objects(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
